{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Iterative train_test split**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original DataFrame:  (373400, 50)\n",
      "\n",
      "Missing Values:\n",
      " Series([], dtype: int64)\n",
      "\n",
      "Duplicate Rows Found: 134040\n",
      "Shape after removing duplicate rows:  (239360, 46)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m oversample_multilabel(X_scaled, y)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Split into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43miterative_train_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[0;32m     85\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Function to print label statistics\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_label_statistics\u001b[39m(y, title):\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\skmultilearn\\model_selection\\iterative_stratification.py:93\u001b[0m, in \u001b[0;36miterative_train_test_split\u001b[1;34m(X, y, test_size)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iteratively stratified train/test split\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    stratified division into train/test split\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m stratifier \u001b[38;5;241m=\u001b[39m IterativeStratification(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, sample_distribution_per_fold\u001b[38;5;241m=\u001b[39m[test_size, \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m-\u001b[39mtest_size])\n\u001b[1;32m---> 93\u001b[0m train_indexes, test_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstratifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m X[train_indexes, :], y[train_indexes, :]\n\u001b[0;32m     96\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m X[test_indexes, :], y[test_indexes, :]\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:416\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         (\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    414\u001b[0m     )\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:147\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    145\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    146\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m    148\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m    149\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:159\u001b[0m, in \u001b[0;36mBaseCrossValidator._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates boolean masks corresponding to test sets.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    By default, delegates to _iter_test_indices(X, y, groups)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_indices(X, y, groups):\n\u001b[0;32m    160\u001b[0m         test_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(_num_samples(X), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    161\u001b[0m         test_mask[test_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\skmultilearn\\model_selection\\iterative_stratification.py:343\u001b[0m, in \u001b[0;36mIterativeStratification._iter_test_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    338\u001b[0m     check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    340\u001b[0m rows, rows_used, all_combinations, per_row_combinations, samples_with_combination, folds \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_stratification(y)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribute_positive_evidence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows_used\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_with_combination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_row_combinations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_negative_evidence(rows_used, folds)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m folds:\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\skmultilearn\\model_selection\\iterative_stratification.py:292\u001b[0m, in \u001b[0;36mIterativeStratification._distribute_positive_evidence\u001b[1;34m(self, rows_used, folds, samples_with_combination, per_row_combinations)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m samples_with_combination[i]:\n\u001b[0;32m    291\u001b[0m             samples_with_combination[i]\u001b[38;5;241m.\u001b[39mremove(row)\n\u001b[1;32m--> 292\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesired_samples_per_combination_per_fold[i][m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesired_samples_per_fold[m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    295\u001b[0m l \u001b[38;5;241m=\u001b[39m _get_most_desired_combination(samples_with_combination)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def oversample_multilabel(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform oversampling for multi-label data while preserving label relationships\n",
    "    Uses SMOTE for numeric features\n",
    "    \"\"\"\n",
    "    # Convert labels to label combination patterns\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    \n",
    "    # Get counts of each unique combination\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    \n",
    "    # Determine if we have enough samples for SMOTE\n",
    "    min_samples = min(combination_counts.values())\n",
    "    \n",
    "    # Choose oversampling strategy based on available samples\n",
    "    if min_samples >= 5:  # SMOTE requires at least k+1 samples (default k=5)\n",
    "        oversample = SMOTE(random_state=random_state, k_neighbors=min(min_samples-1, 5))\n",
    "    else:\n",
    "        oversample = RandomOverSampler(random_state=random_state)\n",
    "    \n",
    "    # Create a temporary dataframe with features and label combinations\n",
    "    temp_df = pd.DataFrame(X.copy())\n",
    "    temp_df['label_combination'] = label_combinations\n",
    "    \n",
    "    # Perform oversampling\n",
    "    X_resampled_temp, y_resampled_temp = oversample.fit_resample(\n",
    "        temp_df.drop('label_combination', axis=1),\n",
    "        temp_df['label_combination']\n",
    "    )\n",
    "    \n",
    "    # Convert back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_resampled_temp],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    return X_resampled_temp, y_resampled\n",
    "# Load Dataset\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "print(\"Shape of original DataFrame: \", df.shape)\n",
    "\n",
    "# Drop Address Column\n",
    "df = df.drop(columns=['Address','Hierarchy Duplication','Futile Abstract Pipeline','Futile Hierarchy'])\n",
    " \n",
    "# Check for Missing Values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "# Drop rows where any label in smell_columns is NaN\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Check for Duplicate Rows\n",
    "duplicates = df[df.duplicated()]\n",
    "print(f\"\\nDuplicate Rows Found: {duplicates.shape[0]}\")\n",
    "df = df.drop_duplicates()\n",
    "print(\"Shape after removing duplicate rows: \", df.shape)\n",
    "\n",
    "# Separate Features and Labels\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "#Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply oversampling\n",
    "X_resampled, y_resampled = oversample_multilabel(X_scaled, y)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(\n",
    "    X_resampled, y_resampled.values, test_size=0.2\n",
    ")\n",
    "\n",
    "# Function to print label statistics\n",
    "def print_label_statistics(y, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for column in y.columns:\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            print(y[column].value_counts())\n",
    "        else:\n",
    "            print(pd.Series(y[:, y.columns.get_loc(column)]).value_counts())\n",
    "            \n",
    "    # Print imbalance ratios\n",
    "    print(\"\\nImbalance Ratios:\")\n",
    "    for column in y.columns:\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            counts = y[column].value_counts()\n",
    "        else:\n",
    "            counts = pd.Series(y[:, y.columns.get_loc(column)]).value_counts()\n",
    "        ratio = counts.max() / counts.min()\n",
    "        print(f\"{column}: 1:{ratio:.2f}\")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(pd.DataFrame(y_resampled, columns=y.columns), \n",
    "                      \"After Oversampling Statistics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Normal Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Dataset Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    238526\n",
      "True        834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    220974\n",
      "True      18386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    235824\n",
      "True       3536\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    220037\n",
      "True      19323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     238985\n",
      "False       375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:286.00\n",
      "Data Class: 1:12.02\n",
      "God Class: 1:66.69\n",
      "Schizofrenic Class: 1:11.39\n",
      "Model Class: 1:637.29\n",
      "\n",
      "After Oversampling Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "0    1791765\n",
      "1     398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "0    1592680\n",
      "1     597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "0    1791765\n",
      "1     398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "0    1194510\n",
      "1     995425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "1    1592680\n",
      "0     597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:4.50\n",
      "Data Class: 1:2.67\n",
      "God Class: 1:4.50\n",
      "Schizofrenic Class: 1:1.20\n",
      "Model Class: 1:2.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split  # Changed from skmultilearn\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def oversample_multilabel(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform oversampling for multi-label data while preserving label relationships\n",
    "    Uses SMOTE for numeric features\n",
    "    \"\"\"\n",
    "    # Convert labels to label combination patterns\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    \n",
    "    # Get counts of each unique combination\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    \n",
    "    # Determine if we have enough samples for SMOTE\n",
    "    min_samples = min(combination_counts.values())\n",
    "    \n",
    "    # Choose oversampling strategy based on available samples\n",
    "    if min_samples >= 5:\n",
    "        oversample = SMOTE(random_state=random_state, k_neighbors=min(min_samples-1, 5))\n",
    "    else:\n",
    "        oversample = RandomOverSampler(random_state=random_state)\n",
    "    \n",
    "    # Perform oversampling directly without creating temporary dataframe\n",
    "    X_resampled_temp, y_resampled_temp = oversample.fit_resample(X, label_combinations)\n",
    "    \n",
    "    # Convert back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_resampled_temp],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    return X_resampled_temp, y_resampled\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', 'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "# Define label columns\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply oversampling\n",
    "X_resampled, y_resampled = oversample_multilabel(X_scaled, y)\n",
    "\n",
    "# Use regular train_test_split instead of iterative_train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=create_label_combinations(y_resampled)  # Stratify by label combinations\n",
    ")\n",
    "\n",
    "# Function to print label statistics\n",
    "def print_label_statistics(y, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for column in y.columns:\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        print(y[column].value_counts())\n",
    "            \n",
    "    # Print imbalance ratios\n",
    "    print(\"\\nImbalance Ratios:\")\n",
    "    for column in y.columns:\n",
    "        counts = y[column].value_counts()\n",
    "        ratio = counts.max() / counts.min()\n",
    "        print(f\"{column}: 1:{ratio:.2f}\")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(y_resampled, \"After Oversampling Statistics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usaing SMOTE and added Label correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing initial label relationships...\n",
      "\n",
      "Initial Label Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class                0.0        0.0       0.0                0.0   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class                0.0  \n",
      "Data Class                 0.0  \n",
      "God Class                  0.0  \n",
      "Schizofrenic Class         0.0  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "\n",
      "Warning: Some label relationships may have been altered during oversampling\n",
      "\n",
      "Original Dataset Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    238526\n",
      "True        834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    220974\n",
      "True      18386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    235824\n",
      "True       3536\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    220037\n",
      "True      19323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     238985\n",
      "False       375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:286.00\n",
      "Data Class: 1:12.02\n",
      "God Class: 1:66.69\n",
      "Schizofrenic Class: 1:11.39\n",
      "Model Class: 1:637.29\n",
      "\n",
      "After Oversampling Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "0    1791765\n",
      "1     398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "0    1592680\n",
      "1     597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "0    1791765\n",
      "1     398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "0    1194510\n",
      "1     995425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "1    1592680\n",
      "0     597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:4.50\n",
      "Data Class: 1:2.67\n",
      "God Class: 1:4.50\n",
      "Schizofrenic Class: 1:1.20\n",
      "Model Class: 1:2.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def analyze_label_relationships(y, title=\"Label Relationships\"):\n",
    "    \"\"\"Analyze and print relationships between labels\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    n_labels = y.shape[1]\n",
    "    relationships = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        for j in range(i+1, n_labels):\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(y.iloc[:,i], y.iloc[:,j])\n",
    "            # Calculate chi-square test\n",
    "            chi2, p_value, _, _ = chi2_contingency(contingency)\n",
    "            relationships.iloc[i,j] = p_value\n",
    "            relationships.iloc[j,i] = p_value\n",
    "    \n",
    "    print(\"\\nLabel correlation p-values (lower = stronger relationship):\")\n",
    "    print(relationships)\n",
    "    return relationships\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def validate_label_preservation(original_y, resampled_y, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Validate that label relationships are preserved after resampling\n",
    "    Returns True if relationships are preserved\n",
    "    \"\"\"\n",
    "    orig_relationships = analyze_label_relationships(original_y, \"Original Relationships\")\n",
    "    new_relationships = analyze_label_relationships(resampled_y, \"Resampled Relationships\")\n",
    "    \n",
    "    # Compare relationship strengths\n",
    "    relationship_preserved = True\n",
    "    for i in range(len(original_y.columns)):\n",
    "        for j in range(i+1, len(original_y.columns)):\n",
    "            orig_sig = orig_relationships.iloc[i,j] < threshold\n",
    "            new_sig = new_relationships.iloc[i,j] < threshold\n",
    "            if orig_sig != new_sig:\n",
    "                print(f\"\\nWarning: Relationship changed between {original_y.columns[i]} and {original_y.columns[j]}\")\n",
    "                relationship_preserved = False\n",
    "    \n",
    "    return relationship_preserved\n",
    "\n",
    "def oversample_multilabel(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform oversampling for multi-label data while preserving label relationships\n",
    "    \"\"\"\n",
    "    # Convert labels to label combination patterns\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    \n",
    "    # Get counts of each unique combination\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    \n",
    "    # Calculate target number for each combination\n",
    "    max_count = max(combination_counts.values())\n",
    "    sampling_strategy = {k: max_count for k in combination_counts.keys()}\n",
    "    \n",
    "    # Determine if we have enough samples for SMOTE\n",
    "    min_samples = min(combination_counts.values())\n",
    "    \n",
    "    if min_samples >= 5:\n",
    "        oversample = SMOTE(\n",
    "            random_state=random_state,\n",
    "            k_neighbors=min(min_samples-1, 5),\n",
    "            sampling_strategy=sampling_strategy\n",
    "        )\n",
    "    else:\n",
    "        oversample = RandomOverSampler(\n",
    "            random_state=random_state,\n",
    "            sampling_strategy=sampling_strategy\n",
    "        )\n",
    "    \n",
    "    # Perform oversampling\n",
    "    X_resampled_temp, y_resampled_temp = oversample.fit_resample(X, label_combinations)\n",
    "    \n",
    "    # Convert back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_resampled_temp],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    # Validate preservation of label relationships\n",
    "    if not validate_label_preservation(y, y_resampled):\n",
    "        print(\"\\nWarning: Some label relationships may have been altered during oversampling\")\n",
    "    \n",
    "    return X_resampled_temp, y_resampled\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', 'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "# Define label columns\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print initial label relationships\n",
    "print(\"\\nAnalyzing initial label relationships...\")\n",
    "analyze_label_relationships(y, \"Initial Label Relationships\")\n",
    "\n",
    "# Apply oversampling\n",
    "X_resampled, y_resampled = oversample_multilabel(X_scaled, y)\n",
    "\n",
    "# Use train_test_split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=create_label_combinations(y_resampled)\n",
    ")\n",
    "\n",
    "def print_label_statistics(y, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for column in y.columns:\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        print(y[column].value_counts())\n",
    "            \n",
    "    print(\"\\nImbalance Ratios:\")\n",
    "    for column in y.columns:\n",
    "        counts = y[column].value_counts()\n",
    "        ratio = counts.max() / counts.min()\n",
    "        print(f\"{column}: 1:{ratio:.2f}\")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(y_resampled, \"After Oversampling Statistics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ssing Cluster-based SMOTE, added ratios for more controlled sampling and Validation of Label Relationships**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing initial label relationships...\n",
      "\n",
      "Initial Label Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "KMeansSMOTE failed, falling back to RandomOverSampler: The 'k_neighbors' parameter of KMeansSMOTE must be an int in the range [1, inf) or an object implementing 'kneighbors' and 'kneighbors_graph'. Got 0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class                0.0        0.0       0.0                0.0   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class                0.0  \n",
      "Data Class                 0.0  \n",
      "God Class                  0.0  \n",
      "Schizofrenic Class         0.0  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "\n",
      "Multilabel Metrics:\n",
      "Hamming Loss: 0.0000\n",
      "Jaccard Score: 0.9985\n",
      "\n",
      "Warning: Some label relationships may have been altered during oversampling\n",
      "\n",
      "Original Dataset Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    238526\n",
      "True        834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    220974\n",
      "True      18386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    235824\n",
      "True       3536\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    220037\n",
      "True      19323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     238985\n",
      "False       375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:286.00\n",
      "Data Class: 1:12.02\n",
      "God Class: 1:66.69\n",
      "Schizofrenic Class: 1:11.39\n",
      "Model Class: 1:637.29\n",
      "\n",
      "After Oversampling Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "0    310160\n",
      "1     51761\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "0    316133\n",
      "1     45788\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "0    318123\n",
      "1     43798\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "0    267135\n",
      "1     94786\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "1    351605\n",
      "0     10316\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:5.99\n",
      "Data Class: 1:6.90\n",
      "God Class: 1:7.26\n",
      "Schizofrenic Class: 1:2.82\n",
      "Model Class: 1:34.08\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import KMeansSMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import hamming_loss, jaccard_score\n",
    "\n",
    "def analyze_label_relationships(y, title=\"Label Relationships\"):\n",
    "    \"\"\"Analyze and print relationships between labels\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    n_labels = y.shape[1]\n",
    "    relationships = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        for j in range(i+1, n_labels):\n",
    "            contingency = pd.crosstab(y.iloc[:,i], y.iloc[:,j])\n",
    "            chi2, p_value, _, _ = chi2_contingency(contingency)\n",
    "            relationships.iloc[i,j] = p_value\n",
    "            relationships.iloc[j,i] = p_value\n",
    "    \n",
    "    print(\"\\nLabel correlation p-values (lower = stronger relationship):\")\n",
    "    print(relationships)\n",
    "    return relationships\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def calculate_multilabel_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate multilabel-specific metrics\"\"\"\n",
    "    metrics = {\n",
    "        'hamming_loss': hamming_loss(y_true, y_pred),\n",
    "        'jaccard_score': jaccard_score(y_true, y_pred, average='samples'),\n",
    "        'label_correlation': analyze_label_relationships(pd.DataFrame(y_pred, columns=y_true.columns))\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def validate_label_preservation(original_y, resampled_y, threshold=0.05):\n",
    "    \"\"\"Validate that label relationships are preserved after resampling\"\"\"\n",
    "    metrics = calculate_multilabel_metrics(original_y, resampled_y[:len(original_y)])\n",
    "    \n",
    "    orig_relationships = analyze_label_relationships(original_y, \"Original Relationships\")\n",
    "    new_relationships = analyze_label_relationships(resampled_y, \"Resampled Relationships\")\n",
    "    \n",
    "    relationship_preserved = True\n",
    "    for i in range(len(original_y.columns)):\n",
    "        for j in range(i+1, len(original_y.columns)):\n",
    "            orig_sig = orig_relationships.iloc[i,j] < threshold\n",
    "            new_sig = new_relationships.iloc[i,j] < threshold\n",
    "            if orig_sig != new_sig:\n",
    "                print(f\"\\nWarning: Relationship changed between {original_y.columns[i]} and {original_y.columns[j]}\")\n",
    "                relationship_preserved = False\n",
    "    \n",
    "    print(\"\\nMultilabel Metrics:\")\n",
    "    print(f\"Hamming Loss: {metrics['hamming_loss']:.4f}\")\n",
    "    print(f\"Jaccard Score: {metrics['jaccard_score']:.4f}\")\n",
    "    \n",
    "    return relationship_preserved\n",
    "\n",
    "def oversample_multilabel(X, y, random_state=42):\n",
    "    \"\"\"Perform oversampling using Cluster-based SMOTE with custom ratios\"\"\"\n",
    "    # Define custom sampling ratios based on domain knowledge\n",
    "    sampling_ratios = {\n",
    "        'Brain Class': 0.3,    # More aggressive for very rare class\n",
    "        'Model Class': 0.3,    # More aggressive for very rare class\n",
    "        'God Class': 0.2,      # Moderate oversampling\n",
    "        'Schizofrenic Class': 0.1,  # Less aggressive\n",
    "        'Data Class': 0.15     # Moderate oversampling\n",
    "    }\n",
    "    \n",
    "    # Convert label combinations for cluster-based sampling\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    \n",
    "    # Calculate sampling strategy based on combinations\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    max_count = max(combination_counts.values())\n",
    "    \n",
    "    # Adjust sampling strategy based on custom ratios\n",
    "    sampling_strategy = {}\n",
    "    for combo in combination_counts.keys():\n",
    "        # Calculate the target count based on the labels present in this combination\n",
    "        combo_labels = [int(c) for c in combo]\n",
    "        ratio_sum = sum(sampling_ratios[col] for col, present in zip(y.columns, combo_labels) if present)\n",
    "        if ratio_sum > 0:\n",
    "            target_count = int(max_count * (ratio_sum / len(sampling_ratios)))\n",
    "            if target_count > combination_counts[combo]:\n",
    "                sampling_strategy[combo] = target_count\n",
    "    \n",
    "    try:\n",
    "        # Try Cluster-based SMOTE first\n",
    "        oversample = KMeansSMOTE(\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            random_state=random_state,\n",
    "            cluster_balance_threshold=0.05,\n",
    "            k_neighbors=min(5, min(combination_counts.values())-1),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        X_resampled_temp, y_resampled_temp = oversample.fit_resample(X, label_combinations)\n",
    "    except Exception as e:\n",
    "        print(f\"KMeansSMOTE failed, falling back to RandomOverSampler: {str(e)}\")\n",
    "        # Fallback to RandomOverSampler if SMOTE fails\n",
    "        oversample = RandomOverSampler(\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        X_resampled_temp, y_resampled_temp = oversample.fit_resample(X, label_combinations)\n",
    "    \n",
    "    # Convert back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_resampled_temp],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    # Validate preservation of label relationships and calculate metrics\n",
    "    if not validate_label_preservation(y, y_resampled):\n",
    "        print(\"\\nWarning: Some label relationships may have been altered during oversampling\")\n",
    "    \n",
    "    return X_resampled_temp, y_resampled\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', 'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print initial label relationships\n",
    "print(\"\\nAnalyzing initial label relationships...\")\n",
    "analyze_label_relationships(y, \"Initial Label Relationships\")\n",
    "\n",
    "# Apply enhanced oversampling\n",
    "X_resampled, y_resampled = oversample_multilabel(X_scaled, y)\n",
    "\n",
    "# Use train_test_split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=create_label_combinations(y_resampled)\n",
    ")\n",
    "\n",
    "def print_label_statistics(y, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for column in y.columns:\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        print(y[column].value_counts())\n",
    "            \n",
    "    print(\"\\nImbalance Ratios:\")\n",
    "    for column in y.columns:\n",
    "        counts = y[column].value_counts()\n",
    "        ratio = counts.max() / counts.min()\n",
    "        print(f\"{column}: 1:{ratio:.2f}\")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(y_resampled, \"After Oversampling Statistics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Multilabel Random OverSampling insted of SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing initial label relationships...\n",
      "\n",
      "Initial Label Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class                0.0        0.0       0.0                0.0   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class                0.0  \n",
      "Data Class                 0.0  \n",
      "God Class                  0.0  \n",
      "Schizofrenic Class         0.0  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "\n",
      "Original Dataset Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    238526\n",
      "True        834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    220974\n",
      "True      18386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    235824\n",
      "True       3536\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    220037\n",
      "True      19323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     238985\n",
      "False       375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:286.00\n",
      "Data Class: 1:12.02\n",
      "God Class: 1:66.69\n",
      "Schizofrenic Class: 1:11.39\n",
      "Model Class: 1:637.29\n",
      "\n",
      "After Oversampling Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    1791765\n",
      "True      398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    1592680\n",
      "True      597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    1791765\n",
      "True      398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    1194510\n",
      "True      995425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     1592680\n",
      "False     597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:4.50\n",
      "Data Class: 1:2.67\n",
      "God Class: 1:4.50\n",
      "Schizofrenic Class: 1:1.20\n",
      "Model Class: 1:2.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "def analyze_label_relationships(y, title=\"Label Relationships\"):\n",
    "    \"\"\"Analyze and print relationships between labels\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    n_labels = y.shape[1]\n",
    "    relationships = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        for j in range(i+1, n_labels):\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(y.iloc[:,i], y.iloc[:,j])\n",
    "            # Calculate chi-square test\n",
    "            chi2, p_value, _, _ = chi2_contingency(contingency)\n",
    "            relationships.iloc[i,j] = p_value\n",
    "            relationships.iloc[j,i] = p_value\n",
    "    \n",
    "    print(\"\\nLabel correlation p-values (lower = stronger relationship):\")\n",
    "    print(relationships)\n",
    "    return relationships\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def validate_label_preservation(original_y, resampled_y, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Validate that label relationships are preserved after resampling\n",
    "    Returns True if relationships are preserved\n",
    "    \"\"\"\n",
    "    orig_relationships = analyze_label_relationships(original_y, \"Original Relationships\")\n",
    "    new_relationships = analyze_label_relationships(resampled_y, \"Resampled Relationships\")\n",
    "    \n",
    "    # Compare relationship strengths\n",
    "    relationship_preserved = True\n",
    "    for i in range(len(original_y.columns)):\n",
    "        for j in range(i+1, len(original_y.columns)):\n",
    "            orig_sig = orig_relationships.iloc[i,j] < threshold\n",
    "            new_sig = new_relationships.iloc[i,j] < threshold\n",
    "            if orig_sig != new_sig:\n",
    "                print(f\"\\nWarning: Relationship changed between {original_y.columns[i]} and {original_y.columns[j]}\")\n",
    "                relationship_preserved = False\n",
    "    \n",
    "    return relationship_preserved\n",
    "\n",
    "def ml_ros(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Multilabel Random OverSampling\n",
    "    Preserves label relationships better than SMOTE for multilabel data\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame(X)\n",
    "    combinations = create_label_combinations(y)\n",
    "    unique_combinations = np.unique(combinations)\n",
    "    \n",
    "    # Get the majority combination count\n",
    "    combination_counts = Counter(combinations)\n",
    "    max_count = max(combination_counts.values())\n",
    "    \n",
    "    X_resampled = []\n",
    "    y_resampled = []\n",
    "    \n",
    "    for combo in unique_combinations:\n",
    "        # Get indices for this combination\n",
    "        indices = np.where(combinations == combo)[0]\n",
    "        n_samples = len(indices)\n",
    "        \n",
    "        # Number of samples needed\n",
    "        n_needed = max_count - n_samples\n",
    "        \n",
    "        # Add original samples\n",
    "        X_resampled.append(X.iloc[indices])\n",
    "        y_resampled.append(y.iloc[indices])\n",
    "        \n",
    "        if n_needed > 0:\n",
    "            # Random oversampling with replacement\n",
    "            resample_idx = np.random.RandomState(random_state).choice(\n",
    "                indices, size=n_needed, replace=True\n",
    "            )\n",
    "            X_resampled.append(X.iloc[resample_idx])\n",
    "            y_resampled.append(y.iloc[resample_idx])\n",
    "    \n",
    "    X_resampled = pd.concat(X_resampled, axis=0)\n",
    "    y_resampled = pd.concat(y_resampled, axis=0)\n",
    "    \n",
    "    return X_resampled.values, y_resampled\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', 'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print initial label relationships\n",
    "print(\"\\nAnalyzing initial label relationships...\")\n",
    "analyze_label_relationships(y, \"Initial Label Relationships\")\n",
    "\n",
    "# Apply ML-ROS instead of SMOTE\n",
    "X_resampled, y_resampled = ml_ros(X_scaled, y)\n",
    "\n",
    "# Validate preservation of label relationships\n",
    "validate_label_preservation(y, y_resampled)\n",
    "\n",
    "# Use train_test_split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=create_label_combinations(y_resampled)\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(pd.DataFrame(y_resampled, columns=y.columns), \n",
    "                      \"After Oversampling Statistics:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

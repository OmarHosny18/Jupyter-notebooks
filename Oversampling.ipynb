{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Iterative train_test split**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original DataFrame:  (373400, 50)\n",
      "\n",
      "Missing Values:\n",
      " Series([], dtype: int64)\n",
      "\n",
      "Duplicate Rows Found: 134040\n",
      "Shape after removing duplicate rows:  (239360, 46)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m oversample_multilabel(X_scaled, y)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Split into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43miterative_train_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[0;32m     85\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Function to print label statistics\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_label_statistics\u001b[39m(y, title):\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\skmultilearn\\model_selection\\iterative_stratification.py:93\u001b[0m, in \u001b[0;36miterative_train_test_split\u001b[1;34m(X, y, test_size)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iteratively stratified train/test split\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    stratified division into train/test split\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m stratifier \u001b[38;5;241m=\u001b[39m IterativeStratification(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, sample_distribution_per_fold\u001b[38;5;241m=\u001b[39m[test_size, \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m-\u001b[39mtest_size])\n\u001b[1;32m---> 93\u001b[0m train_indexes, test_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstratifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m X[train_indexes, :], y[train_indexes, :]\n\u001b[0;32m     96\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m X[test_indexes, :], y[test_indexes, :]\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:416\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         (\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    414\u001b[0m     )\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:147\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    145\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    146\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m    148\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m    149\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:159\u001b[0m, in \u001b[0;36mBaseCrossValidator._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates boolean masks corresponding to test sets.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    By default, delegates to _iter_test_indices(X, y, groups)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_indices(X, y, groups):\n\u001b[0;32m    160\u001b[0m         test_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(_num_samples(X), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    161\u001b[0m         test_mask[test_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\skmultilearn\\model_selection\\iterative_stratification.py:343\u001b[0m, in \u001b[0;36mIterativeStratification._iter_test_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    338\u001b[0m     check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    340\u001b[0m rows, rows_used, all_combinations, per_row_combinations, samples_with_combination, folds \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_stratification(y)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribute_positive_evidence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows_used\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_with_combination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_row_combinations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_negative_evidence(rows_used, folds)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m folds:\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\site-packages\\skmultilearn\\model_selection\\iterative_stratification.py:292\u001b[0m, in \u001b[0;36mIterativeStratification._distribute_positive_evidence\u001b[1;34m(self, rows_used, folds, samples_with_combination, per_row_combinations)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m samples_with_combination[i]:\n\u001b[0;32m    291\u001b[0m             samples_with_combination[i]\u001b[38;5;241m.\u001b[39mremove(row)\n\u001b[1;32m--> 292\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesired_samples_per_combination_per_fold[i][m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesired_samples_per_fold[m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    295\u001b[0m l \u001b[38;5;241m=\u001b[39m _get_most_desired_combination(samples_with_combination)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def oversample_multilabel(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform oversampling for multi-label data while preserving label relationships\n",
    "    Uses SMOTE for numeric features\n",
    "    \"\"\"\n",
    "    # Convert labels to label combination patterns\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    \n",
    "    # Get counts of each unique combination\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    \n",
    "    # Determine if we have enough samples for SMOTE\n",
    "    min_samples = min(combination_counts.values())\n",
    "    \n",
    "    # Choose oversampling strategy based on available samples\n",
    "    if min_samples >= 5:  # SMOTE requires at least k+1 samples (default k=5)\n",
    "        oversample = SMOTE(random_state=random_state, k_neighbors=min(min_samples-1, 5))\n",
    "    else:\n",
    "        oversample = RandomOverSampler(random_state=random_state)\n",
    "    \n",
    "    # Create a temporary dataframe with features and label combinations\n",
    "    temp_df = pd.DataFrame(X.copy())\n",
    "    temp_df['label_combination'] = label_combinations\n",
    "    \n",
    "    # Perform oversampling\n",
    "    X_resampled_temp, y_resampled_temp = oversample.fit_resample(\n",
    "        temp_df.drop('label_combination', axis=1),\n",
    "        temp_df['label_combination']\n",
    "    )\n",
    "    \n",
    "    # Convert back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_resampled_temp],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    return X_resampled_temp, y_resampled\n",
    "# Load Dataset\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "print(\"Shape of original DataFrame: \", df.shape)\n",
    "\n",
    "# Drop Address Column\n",
    "df = df.drop(columns=['Address','Hierarchy Duplication','Futile Abstract Pipeline','Futile Hierarchy'])\n",
    " \n",
    "# Check for Missing Values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "# Drop rows where any label in smell_columns is NaN\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Check for Duplicate Rows\n",
    "duplicates = df[df.duplicated()]\n",
    "print(f\"\\nDuplicate Rows Found: {duplicates.shape[0]}\")\n",
    "df = df.drop_duplicates()\n",
    "print(\"Shape after removing duplicate rows: \", df.shape)\n",
    "\n",
    "# Separate Features and Labels\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "#Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply oversampling\n",
    "X_resampled, y_resampled = oversample_multilabel(X_scaled, y)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(\n",
    "    X_resampled, y_resampled.values, test_size=0.2\n",
    ")\n",
    "\n",
    "# Function to print label statistics\n",
    "def print_label_statistics(y, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for column in y.columns:\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            print(y[column].value_counts())\n",
    "        else:\n",
    "            print(pd.Series(y[:, y.columns.get_loc(column)]).value_counts())\n",
    "            \n",
    "    # Print imbalance ratios\n",
    "    print(\"\\nImbalance Ratios:\")\n",
    "    for column in y.columns:\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            counts = y[column].value_counts()\n",
    "        else:\n",
    "            counts = pd.Series(y[:, y.columns.get_loc(column)]).value_counts()\n",
    "        ratio = counts.max() / counts.min()\n",
    "        print(f\"{column}: 1:{ratio:.2f}\")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(pd.DataFrame(y_resampled, columns=y.columns), \n",
    "                      \"After Oversampling Statistics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Normal Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Apply oversampling\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43moversample_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Use regular train_test_split instead of iterative_train_test_split\u001b[39;00m\n\u001b[0;32m     66\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     67\u001b[0m     X_resampled, \n\u001b[0;32m     68\u001b[0m     y_resampled,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m     stratify\u001b[38;5;241m=\u001b[39mcreate_label_combinations(y_resampled)  \u001b[38;5;66;03m# Stratify by label combinations\u001b[39;00m\n\u001b[0;32m     72\u001b[0m )\n",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m, in \u001b[0;36moversample_multilabel\u001b[1;34m(X, y, random_state)\u001b[0m\n\u001b[0;32m     18\u001b[0m label_combinations \u001b[38;5;241m=\u001b[39m create_label_combinations(y)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Get counts of each unique combination\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m combination_counts \u001b[38;5;241m=\u001b[39m \u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_combinations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Determine if we have enough samples for SMOTE\u001b[39;00m\n\u001b[0;32m     24\u001b[0m min_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(combination_counts\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\collections\\__init__.py:577\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(iterable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Apps\\anaconda3\\lib\\collections\\__init__.py:671\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m         _count_elements(\u001b[38;5;28mself\u001b[39m, iterable)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split  # Changed from skmultilearn\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def oversample_multilabel(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform oversampling for multi-label data while preserving label relationships\n",
    "    Uses SMOTE for numeric features\n",
    "    \"\"\"\n",
    "    # Convert labels to label combination patterns\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    \n",
    "    # Get counts of each unique combination\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    \n",
    "    # Determine if we have enough samples for SMOTE\n",
    "    min_samples = min(combination_counts.values())\n",
    "    \n",
    "    # Choose oversampling strategy based on available samples\n",
    "    if min_samples >= 5:\n",
    "        oversample = SMOTE(random_state=random_state, k_neighbors=min(min_samples-1, 5))\n",
    "    else:\n",
    "        oversample = RandomOverSampler(random_state=random_state)\n",
    "    \n",
    "    # Perform oversampling directly without creating temporary dataframe\n",
    "    X_resampled_temp, y_resampled_temp = oversample.fit_resample(X, label_combinations)\n",
    "    \n",
    "    # Convert back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_resampled_temp],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    return X_resampled_temp, y_resampled\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', 'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "# Define label columns\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply oversampling\n",
    "X_resampled, y_resampled = oversample_multilabel(X_scaled, y)\n",
    "\n",
    "# Use regular train_test_split instead of iterative_train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=create_label_combinations(y_resampled)  # Stratify by label combinations\n",
    ")\n",
    "\n",
    "# Function to print label statistics\n",
    "def print_label_statistics(y, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for column in y.columns:\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        print(y[column].value_counts())\n",
    "            \n",
    "    # Print imbalance ratios\n",
    "    print(\"\\nImbalance Ratios:\")\n",
    "    for column in y.columns:\n",
    "        counts = y[column].value_counts()\n",
    "        ratio = counts.max() / counts.min()\n",
    "        print(f\"{column}: 1:{ratio:.2f}\")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(y_resampled, \"After Oversampling Statistics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usaing SMOTE and added Label correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing initial label relationships...\n",
      "\n",
      "Initial Label Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Performing controlled oversampling...\n",
      "\n",
      "Final dataset sizes:\n",
      "Training set: 729734 samples\n",
      "Test set: 182434 samples\n",
      "\n",
      "Original Dataset Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    238526\n",
      "True        834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    220974\n",
      "True      18386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    235824\n",
      "True       3536\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    220037\n",
      "True      19323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     238985\n",
      "False       375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:286.00\n",
      "Data Class: 1:12.02\n",
      "God Class: 1:66.69\n",
      "Schizofrenic Class: 1:11.39\n",
      "Model Class: 1:637.29\n",
      "\n",
      "After Oversampling Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "0    780773\n",
      "1    131395\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "0    641414\n",
      "1    270754\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "0    776791\n",
      "1    135377\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "1    461874\n",
      "0    450294\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "1    720685\n",
      "0    191483\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:5.94\n",
      "Data Class: 1:2.37\n",
      "God Class: 1:5.74\n",
      "Schizofrenic Class: 1:1.03\n",
      "Model Class: 1:3.76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def analyze_label_relationships(y, title=\"Label Relationships\"):\n",
    "    \"\"\"Analyze and print relationships between labels\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    n_labels = y.shape[1]\n",
    "    relationships = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        for j in range(i+1, n_labels):\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(y.iloc[:,i], y.iloc[:,j])\n",
    "            # Calculate chi-square test\n",
    "            chi2, p_value, _, _ = chi2_contingency(contingency)\n",
    "            relationships.iloc[i,j] = p_value\n",
    "            relationships.iloc[j,i] = p_value\n",
    "    \n",
    "    print(\"\\nLabel correlation p-values (lower = stronger relationship):\")\n",
    "    print(relationships)\n",
    "    return relationships\n",
    "\n",
    "def print_label_statistics(y, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for column in y.columns:\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        print(y[column].value_counts())\n",
    "            \n",
    "    print(\"\\nImbalance Ratios:\")\n",
    "    for column in y.columns:\n",
    "        counts = y[column].value_counts()\n",
    "        ratio = counts.max() / counts.min()\n",
    "        print(f\"{column}: 1:{ratio:.2f}\")\n",
    "\n",
    "def validate_label_preservation(original_y, resampled_y, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Validate that label relationships are preserved after resampling\n",
    "    Returns True if relationships are preserved\n",
    "    \"\"\"\n",
    "    orig_relationships = analyze_label_relationships(original_y, \"Original Relationships\")\n",
    "    new_relationships = analyze_label_relationships(resampled_y, \"Resampled Relationships\")\n",
    "    \n",
    "    # Compare relationship strengths\n",
    "    relationship_preserved = True\n",
    "    for i in range(len(original_y.columns)):\n",
    "        for j in range(i+1, len(original_y.columns)):\n",
    "            orig_sig = orig_relationships.iloc[i,j] < threshold\n",
    "            new_sig = new_relationships.iloc[i,j] < threshold\n",
    "            if orig_sig != new_sig:\n",
    "                print(f\"\\nWarning: Relationship changed between {original_y.columns[i]} and {original_y.columns[j]}\")\n",
    "                relationship_preserved = False\n",
    "    \n",
    "    return relationship_preserved\n",
    "\n",
    "def get_target_ratio(class_name, minority_count, majority_count):\n",
    "    \"\"\"\n",
    "    Calculate target ratio based on class-specific characteristics\n",
    "    Returns target ratio and whether to use aggressive sampling\n",
    "    \"\"\"\n",
    "    current_ratio = minority_count / majority_count\n",
    "    \n",
    "    # Class-specific ratio targets based on domain knowledge and original imbalance\n",
    "    ratio_targets = {\n",
    "        'Brain Class': 0.15,      # Target ~1:6.67 ratio (severe imbalance: 834:238526)\n",
    "        'Data Class': 0.4,        # Target ~1:2.5 ratio (moderate imbalance: 18386:220974)\n",
    "        'God Class': 0.2,         # Target ~1:5 ratio (significant imbalance: 3536:235824)\n",
    "        'Schizofrenic Class': 0.4,# Target ~1:2.5 ratio (moderate imbalance: 19323:220037)\n",
    "        'Model Class': 0.15       # Target ~1:6.67 ratio (severe imbalance: 375:238985)\n",
    "    }\n",
    "    \n",
    "    # Get target ratio for this class\n",
    "    target = ratio_targets.get(class_name, 0.3)  # Default 0.3 if class not found\n",
    "    \n",
    "    # Determine if aggressive sampling is needed based on severity of imbalance\n",
    "    use_aggressive = current_ratio < 0.01  # For extremely imbalanced cases\n",
    "    \n",
    "    return target, use_aggressive\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def oversample_multilabel(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform oversampling for multi-label data with class-specific controlled ratios\n",
    "    \"\"\"\n",
    "    # Convert labels to label combination patterns\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    \n",
    "    # Calculate base sampling strategy\n",
    "    sampling_strategy = {}\n",
    "    max_count = max(combination_counts.values())\n",
    "    \n",
    "    # Analyze each combination to determine appropriate sampling\n",
    "    for combo, count in combination_counts.items():\n",
    "        combo_labels = list(map(int, combo))\n",
    "        \n",
    "        # Calculate target based on the most severe imbalance in this combination\n",
    "        max_target_ratio = 0\n",
    "        for i, (label, present) in enumerate(zip(y.columns, combo_labels)):\n",
    "            if present:  # Only consider classes that are present in this combination\n",
    "                minority_count = count\n",
    "                majority_count = max_count\n",
    "                target_ratio, is_aggressive = get_target_ratio(label, minority_count, majority_count)\n",
    "                if is_aggressive:\n",
    "                    target_ratio *= 1.2  # Boost ratio by 20% for aggressive cases\n",
    "                max_target_ratio = max(max_target_ratio, target_ratio)\n",
    "        \n",
    "        # Calculate target number of samples\n",
    "        target = int(max_count * max_target_ratio)\n",
    "        if target > count:  # Only oversample if target is higher than current count\n",
    "            sampling_strategy[combo] = target\n",
    "    \n",
    "    # Determine if we have enough samples for SMOTE\n",
    "    min_samples = min(combination_counts.values())\n",
    "    \n",
    "    if min_samples >= 5:\n",
    "        oversample = SMOTE(\n",
    "            random_state=random_state,\n",
    "            k_neighbors=min(min_samples-1, 5),\n",
    "            sampling_strategy=sampling_strategy\n",
    "        )\n",
    "    else:\n",
    "        oversample = RandomOverSampler(\n",
    "            random_state=random_state,\n",
    "            sampling_strategy=sampling_strategy\n",
    "        )\n",
    "    \n",
    "    # Perform oversampling\n",
    "    X_resampled_temp, y_resampled_temp = oversample.fit_resample(X, label_combinations)\n",
    "    \n",
    "    # Convert back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_resampled_temp],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    return X_resampled_temp, y_resampled\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', 'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "# Define label columns\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print initial label relationships\n",
    "print(\"\\nAnalyzing initial label relationships...\")\n",
    "analyze_label_relationships(y, \"Initial Label Relationships\")\n",
    "\n",
    "# Apply oversampling\n",
    "print(\"\\nPerforming controlled oversampling...\")\n",
    "X_resampled, y_resampled = oversample_multilabel(X_scaled, y)\n",
    "\n",
    "y_resampled.to_csv('y_resampled.csv', index=False)\n",
    "X_resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "X_resampled_df.to_csv('X_resampled.csv', index=False)\n",
    "# Use train_test_split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=create_label_combinations(y_resampled)\n",
    ")\n",
    " # Print split sizes\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(y_resampled, \"After Oversampling Statistics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding  label relationships more**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial combination counts:\n",
      "Combination 00001: 199085\n",
      "Combination 01001: 17443\n",
      "Combination 00011: 17145\n",
      "Combination 00101: 2504\n",
      "Combination 00111: 1032\n",
      "Combination 01011: 942\n",
      "Combination 10001: 641\n",
      "Combination 00000: 363\n",
      "Combination 10011: 193\n",
      "Combination 00010: 11\n",
      "Combination 01000: 1\n",
      "\n",
      "Applying improved oversampling...\n",
      "\n",
      "Initial sampling strategy:\n",
      "Combination 00001: 199085 samples (original: 199085)\n",
      "Combination 00011: 17145 samples (original: 17145)\n",
      "Combination 10011: 942 samples (original: 193)\n",
      "Combination 00111: 1032 samples (original: 1032)\n",
      "Combination 00101: 2504 samples (original: 2504)\n",
      "Combination 01001: 17443 samples (original: 17443)\n",
      "Combination 01011: 942 samples (original: 942)\n",
      "Combination 00000: 942 samples (original: 363)\n",
      "Combination 10001: 942 samples (original: 641)\n",
      "Combination 00010: 55 samples (original: 11)\n",
      "Combination 01000: 5 samples (original: 1)\n",
      "\n",
      "Oversampling stage 1/5\n",
      "\n",
      "Current stage strategy:\n",
      "Combination 00001: 199085 samples\n",
      "Combination 00011: 17145 samples\n",
      "Combination 10011: 193 samples\n",
      "Combination 00111: 1032 samples\n",
      "Combination 00101: 2504 samples\n",
      "Combination 01001: 17443 samples\n",
      "Combination 01011: 942 samples\n",
      "Combination 00000: 363 samples\n",
      "Combination 10001: 641 samples\n",
      "Combination 00010: 11 samples\n",
      "Combination 01000: 5 samples\n",
      "Using RandomOverSampler due to insufficient samples\n",
      "Current samples: 239364\n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.017056  -0.007241            0.032708   \n",
      "Data Class            -0.017056    1.000000  -0.035321           -0.031229   \n",
      "God Class             -0.007241   -0.035321   1.000000            0.094902   \n",
      "Schizofrenic Class     0.032708   -0.031229   0.094902            1.000000   \n",
      "Model Class            0.002342    0.011030   0.004851            0.007473   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.002342  \n",
      "Data Class             0.011030  \n",
      "God Class              0.004851  \n",
      "Schizofrenic Class     0.007473  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.017058  -0.007241            0.032709   \n",
      "Data Class            -0.017058    1.000000  -0.035325           -0.031243   \n",
      "God Class             -0.007241   -0.035325   1.000000            0.094902   \n",
      "Schizofrenic Class     0.032709   -0.031243   0.094902            1.000000   \n",
      "Model Class            0.002355    0.009516   0.004876            0.007558   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.002355  \n",
      "Data Class             0.009516  \n",
      "God Class              0.004876  \n",
      "Schizofrenic Class     0.007558  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.474086   0.000005  0.029805           0.000314   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.474086  \n",
      "Data Class            0.000005  \n",
      "God Class             0.029805  \n",
      "Schizofrenic Class    0.000314  \n",
      "Model Class                NaN  \n",
      "\n",
      "Relationship Preservation Score: 0.9999\n",
      "\n",
      "Oversampling stage 2/5\n",
      "\n",
      "Current stage strategy:\n",
      "Combination 00001: 199085 samples\n",
      "Combination 00011: 17145 samples\n",
      "Combination 10011: 942 samples\n",
      "Combination 00111: 1032 samples\n",
      "Combination 00101: 2504 samples\n",
      "Combination 01001: 17443 samples\n",
      "Combination 01011: 942 samples\n",
      "Combination 00000: 942 samples\n",
      "Combination 10001: 942 samples\n",
      "Combination 00010: 55 samples\n",
      "Combination 01000: 5 samples\n",
      "Used SMOTE for this stage\n",
      "Current samples: 241037\n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.017056  -0.007241            0.032708   \n",
      "Data Class            -0.017056    1.000000  -0.035321           -0.031229   \n",
      "God Class             -0.007241   -0.035321   1.000000            0.094902   \n",
      "Schizofrenic Class     0.032708   -0.031229   0.094902            1.000000   \n",
      "Model Class            0.002342    0.011030   0.004851            0.007473   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.002342  \n",
      "Data Class             0.011030  \n",
      "God Class              0.004851  \n",
      "Schizofrenic Class     0.007473  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.025509  -0.010830            0.133677   \n",
      "Data Class            -0.025509    1.000000  -0.035068           -0.033494   \n",
      "God Class             -0.010830   -0.035068   1.000000            0.091942   \n",
      "Schizofrenic Class     0.133677   -0.033494   0.091942            1.000000   \n",
      "Model Class            0.005735    0.017354   0.007884            0.006673   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.005735  \n",
      "Data Class             0.017354  \n",
      "God Class              0.007884  \n",
      "Schizofrenic Class     0.006673  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.008397        0.0  0.000185           0.001286   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.008397  \n",
      "Data Class                 0.0  \n",
      "God Class             0.000185  \n",
      "Schizofrenic Class    0.001286  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Schizofrenic Class\n",
      "Correlation change: 0.1010\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "Correlation change: 0.0034\n",
      "\n",
      "Relationship Preservation Score: 0.9894\n",
      "\n",
      "Oversampling stage 3/5\n",
      "\n",
      "Current stage strategy:\n",
      "Combination 00001: 199085 samples\n",
      "Combination 00011: 17145 samples\n",
      "Combination 10011: 942 samples\n",
      "Combination 00111: 1032 samples\n",
      "Combination 00101: 2504 samples\n",
      "Combination 01001: 17443 samples\n",
      "Combination 01011: 942 samples\n",
      "Combination 00000: 942 samples\n",
      "Combination 10001: 942 samples\n",
      "Combination 00010: 55 samples\n",
      "Combination 01000: 5 samples\n",
      "Used SMOTE for this stage\n",
      "Current samples: 241037\n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.017056  -0.007241            0.032708   \n",
      "Data Class            -0.017056    1.000000  -0.035321           -0.031229   \n",
      "God Class             -0.007241   -0.035321   1.000000            0.094902   \n",
      "Schizofrenic Class     0.032708   -0.031229   0.094902            1.000000   \n",
      "Model Class            0.002342    0.011030   0.004851            0.007473   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.002342  \n",
      "Data Class             0.011030  \n",
      "God Class              0.004851  \n",
      "Schizofrenic Class     0.007473  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.025509  -0.010830            0.133677   \n",
      "Data Class            -0.025509    1.000000  -0.035068           -0.033494   \n",
      "God Class             -0.010830   -0.035068   1.000000            0.091942   \n",
      "Schizofrenic Class     0.133677   -0.033494   0.091942            1.000000   \n",
      "Model Class            0.005735    0.017354   0.007884            0.006673   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.005735  \n",
      "Data Class             0.017354  \n",
      "God Class              0.007884  \n",
      "Schizofrenic Class     0.006673  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.008397        0.0  0.000185           0.001286   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.008397  \n",
      "Data Class                 0.0  \n",
      "God Class             0.000185  \n",
      "Schizofrenic Class    0.001286  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Schizofrenic Class\n",
      "Correlation change: 0.1010\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "Correlation change: 0.0034\n",
      "\n",
      "Relationship Preservation Score: 0.9894\n",
      "\n",
      "Oversampling stage 4/5\n",
      "\n",
      "Current stage strategy:\n",
      "Combination 00001: 199085 samples\n",
      "Combination 00011: 17145 samples\n",
      "Combination 10011: 942 samples\n",
      "Combination 00111: 1032 samples\n",
      "Combination 00101: 2504 samples\n",
      "Combination 01001: 17443 samples\n",
      "Combination 01011: 942 samples\n",
      "Combination 00000: 942 samples\n",
      "Combination 10001: 942 samples\n",
      "Combination 00010: 55 samples\n",
      "Combination 01000: 5 samples\n",
      "Used SMOTE for this stage\n",
      "Current samples: 241037\n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.017056  -0.007241            0.032708   \n",
      "Data Class            -0.017056    1.000000  -0.035321           -0.031229   \n",
      "God Class             -0.007241   -0.035321   1.000000            0.094902   \n",
      "Schizofrenic Class     0.032708   -0.031229   0.094902            1.000000   \n",
      "Model Class            0.002342    0.011030   0.004851            0.007473   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.002342  \n",
      "Data Class             0.011030  \n",
      "God Class              0.004851  \n",
      "Schizofrenic Class     0.007473  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.025509  -0.010830            0.133677   \n",
      "Data Class            -0.025509    1.000000  -0.035068           -0.033494   \n",
      "God Class             -0.010830   -0.035068   1.000000            0.091942   \n",
      "Schizofrenic Class     0.133677   -0.033494   0.091942            1.000000   \n",
      "Model Class            0.005735    0.017354   0.007884            0.006673   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.005735  \n",
      "Data Class             0.017354  \n",
      "God Class              0.007884  \n",
      "Schizofrenic Class     0.006673  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.008397        0.0  0.000185           0.001286   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.008397  \n",
      "Data Class                 0.0  \n",
      "God Class             0.000185  \n",
      "Schizofrenic Class    0.001286  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Schizofrenic Class\n",
      "Correlation change: 0.1010\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "Correlation change: 0.0034\n",
      "\n",
      "Relationship Preservation Score: 0.9894\n",
      "\n",
      "Oversampling stage 5/5\n",
      "\n",
      "Current stage strategy:\n",
      "Combination 00001: 199085 samples\n",
      "Combination 00011: 17145 samples\n",
      "Combination 10011: 942 samples\n",
      "Combination 00111: 1032 samples\n",
      "Combination 00101: 2504 samples\n",
      "Combination 01001: 17443 samples\n",
      "Combination 01011: 942 samples\n",
      "Combination 00000: 942 samples\n",
      "Combination 10001: 942 samples\n",
      "Combination 00010: 55 samples\n",
      "Combination 01000: 5 samples\n",
      "Used SMOTE for this stage\n",
      "Current samples: 241037\n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.017056  -0.007241            0.032708   \n",
      "Data Class            -0.017056    1.000000  -0.035321           -0.031229   \n",
      "God Class             -0.007241   -0.035321   1.000000            0.094902   \n",
      "Schizofrenic Class     0.032708   -0.031229   0.094902            1.000000   \n",
      "Model Class            0.002342    0.011030   0.004851            0.007473   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.002342  \n",
      "Data Class             0.011030  \n",
      "God Class              0.004851  \n",
      "Schizofrenic Class     0.007473  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label Correlations:\n",
      "                    Brain Class  Data Class  God Class  Schizofrenic Class  \\\n",
      "Brain Class            1.000000   -0.025509  -0.010830            0.133677   \n",
      "Data Class            -0.025509    1.000000  -0.035068           -0.033494   \n",
      "God Class             -0.010830   -0.035068   1.000000            0.091942   \n",
      "Schizofrenic Class     0.133677   -0.033494   0.091942            1.000000   \n",
      "Model Class            0.005735    0.017354   0.007884            0.006673   \n",
      "\n",
      "                    Model Class  \n",
      "Brain Class            0.005735  \n",
      "Data Class             0.017354  \n",
      "God Class              0.007884  \n",
      "Schizofrenic Class     0.006673  \n",
      "Model Class            1.000000  \n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.008397        0.0  0.000185           0.001286   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.008397  \n",
      "Data Class                 0.0  \n",
      "God Class             0.000185  \n",
      "Schizofrenic Class    0.001286  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Schizofrenic Class\n",
      "Correlation change: 0.1010\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "Correlation change: 0.0034\n",
      "\n",
      "Relationship Preservation Score: 0.9894\n",
      "\n",
      "Analyzing final dataset...\n",
      "\n",
      "Final Dataset Statistics\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "0    239153\n",
      "1      1884\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio: 1:126.94\n",
      "Positive class percentage: 0.78%\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "0    222647\n",
      "1     18390\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio: 1:12.11\n",
      "Positive class percentage: 7.63%\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "0    237501\n",
      "1      3536\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio: 1:67.17\n",
      "Positive class percentage: 1.47%\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "0    220921\n",
      "1     20116\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio: 1:10.98\n",
      "Positive class percentage: 8.35%\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "1    240035\n",
      "0      1002\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio: 1:239.56\n",
      "Positive class percentage: 99.58%\n",
      "\n",
      "Label co-occurrence counts:\n",
      "Brain Class + Data Class: 0 (0.00%)\n",
      "Brain Class + God Class: 0 (0.00%)\n",
      "Brain Class + Schizofrenic Class: 942 (0.39%)\n",
      "Brain Class + Model Class: 1884 (0.78%)\n",
      "Data Class + God Class: 0 (0.00%)\n",
      "Data Class + Schizofrenic Class: 942 (0.39%)\n",
      "Data Class + Model Class: 18385 (7.63%)\n",
      "God Class + Schizofrenic Class: 1032 (0.43%)\n",
      "God Class + Model Class: 3536 (1.47%)\n",
      "Schizofrenic Class + Model Class: 20061 (8.32%)\n",
      "\n",
      "Train/Test split sizes:\n",
      "Training set: (192829, 41)\n",
      "Test set: (48208, 41)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def analyze_label_relationships(y, title=\"Label Relationships\"):\n",
    "    \"\"\"Analyze and print relationships between labels\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    n_labels = y.shape[1]\n",
    "    relationships = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    # Calculate correlations for comparison\n",
    "    correlations = y.corr()\n",
    "    print(\"\\nLabel Correlations:\")\n",
    "    print(correlations)\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        for j in range(i+1, n_labels):\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(y.iloc[:,i], y.iloc[:,j])\n",
    "            # Calculate chi-square test\n",
    "            chi2, p_value, _, _ = chi2_contingency(contingency)\n",
    "            relationships.iloc[i,j] = p_value\n",
    "            relationships.iloc[j,i] = p_value\n",
    "    \n",
    "    print(\"\\nLabel correlation p-values (lower = stronger relationship):\")\n",
    "    print(relationships)\n",
    "    return relationships, correlations\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def measure_relationship_preservation(original_y, resampled_y):\n",
    "    \"\"\"\n",
    "    Quantify how well label relationships are preserved\n",
    "    Returns a score between 0 and 1 (1 = perfect preservation)\n",
    "    \"\"\"\n",
    "    orig_corr = original_y.corr().abs()\n",
    "    new_corr = resampled_y.corr().abs()\n",
    "    \n",
    "    # Calculate difference in correlation matrices\n",
    "    diff = np.abs(orig_corr - new_corr)\n",
    "    \n",
    "    # Return preservation score\n",
    "    preservation_score = 1 - (diff.sum().sum() / (orig_corr.shape[0] * orig_corr.shape[1]))\n",
    "    print(f\"\\nRelationship Preservation Score: {preservation_score:.4f}\")\n",
    "    return preservation_score\n",
    "\n",
    "def validate_label_preservation(original_y, resampled_y, threshold=0.05, correlation_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Validate that label relationships are preserved after resampling\n",
    "    Returns True if relationships are preserved\n",
    "    \"\"\"\n",
    "    orig_relationships, orig_corr = analyze_label_relationships(original_y, \"Original Relationships\")\n",
    "    new_relationships, new_corr = analyze_label_relationships(resampled_y, \"Resampled Relationships\")\n",
    "    \n",
    "    # Compare relationship strengths\n",
    "    relationship_preserved = True\n",
    "    warnings = []\n",
    "    \n",
    "    for i in range(len(original_y.columns)):\n",
    "        for j in range(i+1, len(original_y.columns)):\n",
    "            # Check statistical significance changes\n",
    "            orig_sig = orig_relationships.iloc[i,j] < threshold\n",
    "            new_sig = new_relationships.iloc[i,j] < threshold\n",
    "            \n",
    "            # Check correlation changes\n",
    "            corr_change = abs(orig_corr.iloc[i,j] - new_corr.iloc[i,j])\n",
    "            \n",
    "            if orig_sig != new_sig or corr_change > correlation_threshold:\n",
    "                warning = f\"Warning: Relationship changed between {original_y.columns[i]} and {original_y.columns[j]}\"\n",
    "                warning += f\"\\nCorrelation change: {corr_change:.4f}\"\n",
    "                warnings.append(warning)\n",
    "                relationship_preserved = False\n",
    "    \n",
    "    if warnings:\n",
    "        print(\"\\n\" + \"\\n\".join(warnings))\n",
    "    \n",
    "    # Calculate and print preservation score\n",
    "    preservation_score = measure_relationship_preservation(original_y, resampled_y)\n",
    "    \n",
    "    return relationship_preserved, preservation_score\n",
    "\n",
    "def improved_oversample_multilabel(X, y, max_ratio=10, min_samples_smote=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Enhanced oversampling for multi-label data with controlled ratios\n",
    "    and better relationship preservation\n",
    "    \"\"\"\n",
    "    # Convert labels to label combination patterns\n",
    "    label_combinations = create_label_combinations(y)\n",
    "    combination_counts = Counter(label_combinations)\n",
    "    \n",
    "    # Calculate target counts while ensuring integers\n",
    "    median_count = int(np.median(list(combination_counts.values())))\n",
    "    max_count = max(combination_counts.values())\n",
    "    \n",
    "    # Ensure we don't sample less than original counts and use integers\n",
    "    sampling_strategy = {\n",
    "        k: int(max(\n",
    "            v,  # Keep at least original count\n",
    "            min(\n",
    "                median_count,  # Target median\n",
    "                int(max_ratio * v)  # Cap at max_ratio times original\n",
    "            )\n",
    "        ))\n",
    "        for k, v in combination_counts.items()\n",
    "    }\n",
    "    \n",
    "    # Print sampling strategy for debugging\n",
    "    print(\"\\nInitial sampling strategy:\")\n",
    "    for k, v in sampling_strategy.items():\n",
    "        print(f\"Combination {k}: {v} samples (original: {combination_counts[k]})\")\n",
    "    \n",
    "    # Progressive oversampling\n",
    "    X_current, y_current = X.copy(), label_combinations.copy()\n",
    "    \n",
    "    # Calculate stages based on actual counts\n",
    "    min_target = min(sampling_strategy.values())\n",
    "    max_target = max(sampling_strategy.values())\n",
    "    stages = np.linspace(min_target, max_target, num=5)\n",
    "    \n",
    "    for stage_idx, target_size in enumerate(stages):\n",
    "        print(f\"\\nOversampling stage {stage_idx + 1}/{len(stages)}\")\n",
    "        \n",
    "        # Ensure integer values in current strategy\n",
    "        current_strategy = {\n",
    "            k: int(max(v, min(sampling_strategy[k], target_size))) \n",
    "            for k, v in combination_counts.items()\n",
    "        }\n",
    "        \n",
    "        # Print current stage strategy for debugging\n",
    "        print(\"\\nCurrent stage strategy:\")\n",
    "        for k, v in current_strategy.items():\n",
    "            print(f\"Combination {k}: {v} samples\")\n",
    "        \n",
    "        # Determine if we can use SMOTE\n",
    "        min_samples = min(Counter(y_current).values())\n",
    "        \n",
    "        if min_samples >= min_samples_smote:\n",
    "            try:\n",
    "                oversample = SMOTE(\n",
    "                    random_state=random_state,\n",
    "                    k_neighbors=min(min_samples-1, 5),\n",
    "                    sampling_strategy=current_strategy\n",
    "                )\n",
    "                X_current, y_current = oversample.fit_resample(X_current, y_current)\n",
    "                print(\"Used SMOTE for this stage\")\n",
    "            except (ValueError, RuntimeError) as e:\n",
    "                print(f\"SMOTE failed: {str(e)}\")\n",
    "                print(\"Falling back to RandomOverSampler\")\n",
    "                oversample = RandomOverSampler(\n",
    "                    random_state=random_state,\n",
    "                    sampling_strategy=current_strategy\n",
    "                )\n",
    "                X_current, y_current = oversample.fit_resample(X_current, y_current)\n",
    "        else:\n",
    "            print(\"Using RandomOverSampler due to insufficient samples\")\n",
    "            oversample = RandomOverSampler(\n",
    "                random_state=random_state,\n",
    "                sampling_strategy=current_strategy\n",
    "            )\n",
    "            X_current, y_current = oversample.fit_resample(X_current, y_current)\n",
    "        \n",
    "        # Convert current state back to original format for relationship validation\n",
    "        y_temp = pd.DataFrame([list(map(int, combo)) for combo in y_current],\n",
    "                            columns=y.columns)\n",
    "        print(f\"Current samples: {len(y_current)}\")\n",
    "        _, preservation_score = validate_label_preservation(y, y_temp)\n",
    "        \n",
    "        if preservation_score < 0.7:\n",
    "            print(f\"Warning: Low preservation score ({preservation_score:.4f}) at stage {stage_idx + 1}\")\n",
    "    \n",
    "    # Convert final result back to original format\n",
    "    y_resampled = pd.DataFrame([list(map(int, combo)) for combo in y_current],\n",
    "                              columns=y.columns)\n",
    "    \n",
    "    return X_current, y_resampled\n",
    "\n",
    "def print_label_statistics(y, title):\n",
    "    \"\"\"Print detailed statistics about label distributions\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    \n",
    "    # Individual label statistics\n",
    "    for column in y.columns:\n",
    "        counts = y[column].value_counts()\n",
    "        print(f\"\\nValue counts for {column}:\")\n",
    "        print(counts)\n",
    "        \n",
    "        ratio = counts.max() / counts.min()\n",
    "        percentage = (counts[1] if 1 in counts else 0) / len(y) * 100\n",
    "        \n",
    "        print(f\"Imbalance Ratio: 1:{ratio:.2f}\")\n",
    "        print(f\"Positive class percentage: {percentage:.2f}%\")\n",
    "    \n",
    "    # Co-occurrence statistics\n",
    "    print(\"\\nLabel co-occurrence counts:\")\n",
    "    for i, col1 in enumerate(y.columns):\n",
    "        for j, col2 in enumerate(y.columns[i+1:], i+1):\n",
    "            co_occurrence = ((y[col1] == 1) & (y[col2] == 1)).sum()\n",
    "            total = len(y)\n",
    "            print(f\"{col1} + {col2}: {co_occurrence} ({(co_occurrence/total)*100:.2f}%)\")\n",
    "\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', \n",
    "                         'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "    # Define label columns\n",
    "label_columns = [\n",
    "        'Brain Class', 'Data Class', \n",
    "        'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "    # Separate features and labels\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "    # Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Print initial statistics and relationships\n",
    "# Print combination counts before oversampling\n",
    "initial_combinations = create_label_combinations(y)\n",
    "initial_counts = Counter(initial_combinations)\n",
    "print(\"\\nInitial combination counts:\")\n",
    "for combo, count in initial_counts.most_common():\n",
    "    print(f\"Combination {combo}: {count}\")\n",
    "\n",
    "    # Apply improved oversampling\n",
    "print(\"\\nApplying improved oversampling...\")\n",
    "X_resampled, y_resampled = improved_oversample_multilabel(\n",
    "        X_scaled, \n",
    "        y,\n",
    "        max_ratio=5,\n",
    "        min_samples_smote=5,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Print final statistics\n",
    "print(\"\\nAnalyzing final dataset...\")\n",
    "print_label_statistics(y_resampled, \"Final Dataset Statistics\")\n",
    "\n",
    "    # Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_resampled, \n",
    "        y_resampled,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=create_label_combinations(y_resampled)\n",
    "    )\n",
    "\n",
    "print(\"\\nTrain/Test split sizes:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Multilabel Random OverSampling insted of SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing initial label relationships...\n",
      "\n",
      "Initial Label Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Original Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0  0.000677                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class             0.000677        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class           0.479294        0.0  0.030856           0.000369   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class           0.479294  \n",
      "Data Class                 0.0  \n",
      "God Class             0.030856  \n",
      "Schizofrenic Class    0.000369  \n",
      "Model Class                NaN  \n",
      "\n",
      "Resampled Relationships\n",
      "\n",
      "Label correlation p-values (lower = stronger relationship):\n",
      "                   Brain Class Data Class God Class Schizofrenic Class  \\\n",
      "Brain Class                NaN        0.0       0.0                0.0   \n",
      "Data Class                 0.0        NaN       0.0                0.0   \n",
      "God Class                  0.0        0.0       NaN                0.0   \n",
      "Schizofrenic Class         0.0        0.0       0.0                NaN   \n",
      "Model Class                0.0        0.0       0.0                0.0   \n",
      "\n",
      "                   Model Class  \n",
      "Brain Class                0.0  \n",
      "Data Class                 0.0  \n",
      "God Class                  0.0  \n",
      "Schizofrenic Class         0.0  \n",
      "Model Class                NaN  \n",
      "\n",
      "Warning: Relationship changed between Brain Class and Model Class\n",
      "\n",
      "Original Dataset Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    238526\n",
      "True        834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    220974\n",
      "True      18386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    235824\n",
      "True       3536\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    220037\n",
      "True      19323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     238985\n",
      "False       375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:286.00\n",
      "Data Class: 1:12.02\n",
      "God Class: 1:66.69\n",
      "Schizofrenic Class: 1:11.39\n",
      "Model Class: 1:637.29\n",
      "\n",
      "After Oversampling Statistics:\n",
      "\n",
      "Value counts for Brain Class:\n",
      "Brain Class\n",
      "False    1791765\n",
      "True      398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Data Class:\n",
      "Data Class\n",
      "False    1592680\n",
      "True      597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for God Class:\n",
      "God Class\n",
      "False    1791765\n",
      "True      398170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Schizofrenic Class:\n",
      "Schizofrenic Class\n",
      "False    1194510\n",
      "True      995425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Model Class:\n",
      "Model Class\n",
      "True     1592680\n",
      "False     597255\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance Ratios:\n",
      "Brain Class: 1:4.50\n",
      "Data Class: 1:2.67\n",
      "God Class: 1:4.50\n",
      "Schizofrenic Class: 1:1.20\n",
      "Model Class: 1:2.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "def analyze_label_relationships(y, title=\"Label Relationships\"):\n",
    "    \"\"\"Analyze and print relationships between labels\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    n_labels = y.shape[1]\n",
    "    relationships = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        for j in range(i+1, n_labels):\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(y.iloc[:,i], y.iloc[:,j])\n",
    "            # Calculate chi-square test\n",
    "            chi2, p_value, _, _ = chi2_contingency(contingency)\n",
    "            relationships.iloc[i,j] = p_value\n",
    "            relationships.iloc[j,i] = p_value\n",
    "    \n",
    "    print(\"\\nLabel correlation p-values (lower = stronger relationship):\")\n",
    "    print(relationships)\n",
    "    return relationships\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Convert multi-label data into unique combination patterns\"\"\"\n",
    "    return np.array([''.join(map(str, row)) for row in y.astype(int).values])\n",
    "\n",
    "def validate_label_preservation(original_y, resampled_y, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Validate that label relationships are preserved after resampling\n",
    "    Returns True if relationships are preserved\n",
    "    \"\"\"\n",
    "    orig_relationships = analyze_label_relationships(original_y, \"Original Relationships\")\n",
    "    new_relationships = analyze_label_relationships(resampled_y, \"Resampled Relationships\")\n",
    "    \n",
    "    # Compare relationship strengths\n",
    "    relationship_preserved = True\n",
    "    for i in range(len(original_y.columns)):\n",
    "        for j in range(i+1, len(original_y.columns)):\n",
    "            orig_sig = orig_relationships.iloc[i,j] < threshold\n",
    "            new_sig = new_relationships.iloc[i,j] < threshold\n",
    "            if orig_sig != new_sig:\n",
    "                print(f\"\\nWarning: Relationship changed between {original_y.columns[i]} and {original_y.columns[j]}\")\n",
    "                relationship_preserved = False\n",
    "    \n",
    "    return relationship_preserved\n",
    "\n",
    "def ml_ros(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Multilabel Random OverSampling\n",
    "    Preserves label relationships better than SMOTE for multilabel data\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame(X)\n",
    "    combinations = create_label_combinations(y)\n",
    "    unique_combinations = np.unique(combinations)\n",
    "    \n",
    "    # Get the majority combination count\n",
    "    combination_counts = Counter(combinations)\n",
    "    max_count = max(combination_counts.values())\n",
    "    \n",
    "    X_resampled = []\n",
    "    y_resampled = []\n",
    "    \n",
    "    for combo in unique_combinations:\n",
    "        # Get indices for this combination\n",
    "        indices = np.where(combinations == combo)[0]\n",
    "        n_samples = len(indices)\n",
    "        \n",
    "        # Number of samples needed\n",
    "        n_needed = max_count - n_samples\n",
    "        \n",
    "        # Add original samples\n",
    "        X_resampled.append(X.iloc[indices])\n",
    "        y_resampled.append(y.iloc[indices])\n",
    "        \n",
    "        if n_needed > 0:\n",
    "            # Random oversampling with replacement\n",
    "            resample_idx = np.random.RandomState(random_state).choice(\n",
    "                indices, size=n_needed, replace=True\n",
    "            )\n",
    "            X_resampled.append(X.iloc[resample_idx])\n",
    "            y_resampled.append(y.iloc[resample_idx])\n",
    "    \n",
    "    X_resampled = pd.concat(X_resampled, axis=0)\n",
    "    y_resampled = pd.concat(y_resampled, axis=0)\n",
    "    \n",
    "    return X_resampled.values, y_resampled\n",
    "df = pd.read_csv('Data/New-Class-smell.csv')\n",
    "df = df.drop(columns=['Address', 'Hierarchy Duplication', 'Futile Abstract Pipeline', 'Futile Hierarchy'])\n",
    "\n",
    "label_columns = [\n",
    "    'Brain Class', 'Data Class', \n",
    "    'God Class', 'Schizofrenic Class', 'Model Class'\n",
    "]\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "X = df.drop(columns=label_columns)\n",
    "y = df[label_columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print initial label relationships\n",
    "print(\"\\nAnalyzing initial label relationships...\")\n",
    "analyze_label_relationships(y, \"Initial Label Relationships\")\n",
    "\n",
    "# Apply ML-ROS instead of SMOTE\n",
    "X_resampled, y_resampled = ml_ros(X_scaled, y)\n",
    "\n",
    "# Validate preservation of label relationships\n",
    "validate_label_preservation(y, y_resampled)\n",
    "\n",
    "# Use train_test_split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=create_label_combinations(y_resampled)\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "print_label_statistics(y, \"Original Dataset Statistics:\")\n",
    "print_label_statistics(pd.DataFrame(y_resampled, columns=y.columns), \n",
    "                      \"After Oversampling Statistics:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 373400 entries, 0 to 373399\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Address                   373400 non-null  object \n",
      " 1   Brain Class               373400 non-null  bool   \n",
      " 2   Data Class                373400 non-null  bool   \n",
      " 3   Futile Abstract Pipeline  373400 non-null  bool   \n",
      " 4   Futile Hierarchy          373400 non-null  bool   \n",
      " 5   God Class                 373400 non-null  bool   \n",
      " 6   Hierarchy Duplication     373400 non-null  bool   \n",
      " 7   Model Class               373400 non-null  bool   \n",
      " 8   Schizofrenic Class        373400 non-null  bool   \n",
      " 9   ABUSEINH                  373400 non-null  int64  \n",
      " 10  AMW                       373400 non-null  float64\n",
      " 11  ATFD                      373400 non-null  int64  \n",
      " 12  BOvM                      373400 non-null  int64  \n",
      " 13  BUR                       373400 non-null  float64\n",
      " 14  CBO                       373400 non-null  int64  \n",
      " 15  CC                        373400 non-null  int64  \n",
      " 16  CM                        373400 non-null  int64  \n",
      " 17  CRIX                      373400 non-null  float64\n",
      " 18  DAC                       373400 non-null  int64  \n",
      " 19  DIT                       373400 non-null  int64  \n",
      " 20  EDUPCLS                   373400 non-null  int64  \n",
      " 21  FANOUT                    373400 non-null  int64  \n",
      " 22  FDP                       373400 non-null  int64  \n",
      " 23  GREEDY                    373400 non-null  int64  \n",
      " 24  HDUPCLS                   373400 non-null  int64  \n",
      " 25  HIT                       373400 non-null  int64  \n",
      " 26  IDUPLINES                 373400 non-null  int64  \n",
      " 27  LOCC                      373400 non-null  int64  \n",
      " 28  NAS                       373400 non-null  int64  \n",
      " 29  NAbsM                     373400 non-null  int64  \n",
      " 30  NDU                       373400 non-null  int64  \n",
      " 31  NOA                       373400 non-null  int64  \n",
      " 32  NOAM                      373400 non-null  int64  \n",
      " 33  NOD                       373400 non-null  int64  \n",
      " 34  NODD                      373400 non-null  int64  \n",
      " 35  NOM                       373400 non-null  int64  \n",
      " 36  NOPA                      373400 non-null  int64  \n",
      " 37  NProtM                    373400 non-null  int64  \n",
      " 38  NSPECM                    373400 non-null  int64  \n",
      " 39  NTempF                    373400 non-null  int64  \n",
      " 40  NrBM                      373400 non-null  int64  \n",
      " 41  NrEC                      373400 non-null  int64  \n",
      " 42  NrFE                      373400 non-null  int64  \n",
      " 43  NrIC                      373400 non-null  int64  \n",
      " 44  NrSS                      373400 non-null  int64  \n",
      " 45  PNAS                      373400 non-null  float64\n",
      " 46  SCHIZO                    373400 non-null  int64  \n",
      " 47  TCC                       373400 non-null  float64\n",
      " 48  WMC                       373400 non-null  int64  \n",
      " 49  WOC                       373400 non-null  float64\n",
      "dtypes: bool(8), float64(6), int64(35), object(1)\n",
      "memory usage: 122.5+ MB\n",
      "model 1 F1 score on val dataset:  0.8194444444444444\n",
      "model 2 F1 score on val dataset:  0.49707602339181284\n",
      "model 3 F1 score on val dataset:  0.5182926829268293\n",
      "RFC_None_* Accuracy score on test: 0.9990759341100843\n",
      "RFC_None_* Precision score on test: 0.9902912621359223\n",
      "RFC_None_* ROC score on test: 0.9999536517962891\n",
      "RFC_None_* F1 score on test: 0.7472527472527473\n",
      "RFC_None_* Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74500\n",
      "           1       0.99      0.60      0.75       170\n",
      "\n",
      "    accuracy                           1.00     74670\n",
      "   macro avg       0.99      0.80      0.87     74670\n",
      "weighted avg       1.00      1.00      1.00     74670\n",
      "\n",
      "RFC_unsam_80_20 Accuracy score on test: 0.9950582563278425\n",
      "RFC_unsam_80_20 Precision score on test: 0.31539888682745826\n",
      "RFC_unsam_80_20 ROC score on test: 0.9987632056849585\n",
      "RFC_unsam_80_20 F1 score on test: 0.4795486600846262\n",
      "RFC_unsam_80_20 Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74500\n",
      "           1       0.32      1.00      0.48       170\n",
      "\n",
      "    accuracy                           1.00     74670\n",
      "   macro avg       0.66      1.00      0.74     74670\n",
      "weighted avg       1.00      1.00      1.00     74670\n",
      "\n",
      "RFC_unsam_75_25 Accuracy score on test: 0.994817195660908\n",
      "RFC_unsam_75_25 Precision score on test: 0.3052064631956912\n",
      "RFC_unsam_75_25 ROC score on test: 0.9978395578365573\n",
      "RFC_unsam_75_25 F1 score on test: 0.4676753782668501\n",
      "RFC_unsam_75_25 Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     74500\n",
      "           1       0.31      1.00      0.47       170\n",
      "\n",
      "    accuracy                           0.99     74670\n",
      "   macro avg       0.65      1.00      0.73     74670\n",
      "weighted avg       1.00      0.99      1.00     74670\n",
      "\n",
      "RFC_unsam_60_40 Accuracy score on test: 0.994147582697201\n",
      "RFC_unsam_60_40 Precision score on test: 0.2800658978583196\n",
      "RFC_unsam_60_40 ROC score on test: 0.9978229767074615\n",
      "RFC_unsam_60_40 F1 score on test: 0.4375804375804376\n",
      "RFC_unsam_60_40 Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     74500\n",
      "           1       0.28      1.00      0.44       170\n",
      "\n",
      "    accuracy                           0.99     74670\n",
      "   macro avg       0.64      1.00      0.72     74670\n",
      "weighted avg       1.00      0.99      1.00     74670\n",
      "\n",
      "RFC_oversam_RandomOverSampler Accuracy score on test: 0.9953127092540511\n",
      "RFC_oversam_RandomOverSampler Precision score on test: 0.3269230769230769\n",
      "RFC_oversam_RandomOverSampler ROC score on test: 0.9999698381365969\n",
      "RFC_oversam_RandomOverSampler F1 score on test: 0.4927536231884058\n",
      "RFC_oversam_RandomOverSampler Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74500\n",
      "           1       0.33      1.00      0.49       170\n",
      "\n",
      "    accuracy                           1.00     74670\n",
      "   macro avg       0.66      1.00      0.75     74670\n",
      "weighted avg       1.00      1.00      1.00     74670\n",
      "\n",
      "RFC_oversam_SMOTE Accuracy score on test: 0.9952859247355029\n",
      "RFC_oversam_SMOTE Precision score on test: 0.32567049808429116\n",
      "RFC_oversam_SMOTE ROC score on test: 0.9994340702724043\n",
      "RFC_oversam_SMOTE F1 score on test: 0.4913294797687861\n",
      "RFC_oversam_SMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74500\n",
      "           1       0.33      1.00      0.49       170\n",
      "\n",
      "    accuracy                           1.00     74670\n",
      "   macro avg       0.66      1.00      0.74     74670\n",
      "weighted avg       1.00      1.00      1.00     74670\n",
      "\n",
      "RFC_oversam_BorderlineSMOTE Accuracy score on test: 0.995299316994777\n",
      "RFC_oversam_BorderlineSMOTE Precision score on test: 0.32629558541266795\n",
      "RFC_oversam_BorderlineSMOTE ROC score on test: 0.9988822739834189\n",
      "RFC_oversam_BorderlineSMOTE F1 score on test: 0.492040520984081\n",
      "RFC_oversam_BorderlineSMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74500\n",
      "           1       0.33      1.00      0.49       170\n",
      "\n",
      "    accuracy                           1.00     74670\n",
      "   macro avg       0.66      1.00      0.74     74670\n",
      "weighted avg       1.00      1.00      1.00     74670\n",
      "\n",
      "RFC_oversam_SVMSMOTE Accuracy score on test: 0.9949779027721977\n",
      "RFC_oversam_SVMSMOTE Precision score on test: 0.3119266055045872\n",
      "RFC_oversam_SVMSMOTE ROC score on test: 0.9996345834978287\n",
      "RFC_oversam_SVMSMOTE F1 score on test: 0.4755244755244755\n",
      "RFC_oversam_SVMSMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     74500\n",
      "           1       0.31      1.00      0.48       170\n",
      "\n",
      "    accuracy                           0.99     74670\n",
      "   macro avg       0.66      1.00      0.74     74670\n",
      "weighted avg       1.00      0.99      1.00     74670\n",
      "\n",
      "RFC_oversam_ADASYN Accuracy score on test: 0.9952859247355029\n",
      "RFC_oversam_ADASYN Precision score on test: 0.32567049808429116\n",
      "RFC_oversam_ADASYN ROC score on test: 0.9994367943150415\n",
      "RFC_oversam_ADASYN F1 score on test: 0.4913294797687861\n",
      "RFC_oversam_ADASYN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74500\n",
      "           1       0.33      1.00      0.49       170\n",
      "\n",
      "    accuracy                           1.00     74670\n",
      "   macro avg       0.66      1.00      0.74     74670\n",
      "weighted avg       1.00      1.00      1.00     74670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1. LOADING & PRE-PROCESSING CLASS-LEVEL DATASET\n",
    "# Load class-level dataset\n",
    "df = pd.read_csv('New-Class-smell.csv', low_memory=False)\n",
    "df.info()\n",
    "\n",
    "# Check missing data in dataset\n",
    "for col in df.columns:\n",
    "  missing_data=df[col].isna().sum()\n",
    "  if (missing_data>0):\n",
    "    print(f\"column {col} has {missing_data} missing data\")\n",
    "\n",
    "# Define and initialise a predictive result dataset\n",
    "rs= pd.DataFrame({'Code_smell':[],'Algo':[],'Balance':[],'Ratio':[] , 'Accuracy':[],'Precision':[], 'F1_score':[],'AUC':[]})\n",
    "\n",
    "# 2. BUILDING THE MACHINELEARNING MODEL\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, roc_auc_score, f1_score\n",
    "def _train_and_test(model, _data_train, algo):\n",
    "  global newResult, accuracy,precision,f1,roc\n",
    "  model.fit(_data_train[features], _data_train[target])\n",
    "  predictions = model.predict_proba(data_test[features])\n",
    "  pred_label = model.predict(data_test[features]) \n",
    "  accuracy = accuracy_score(data_test[target], pred_label)\n",
    "  precision = precision_score(data_test[target], pred_label)\n",
    "  f1 = f1_score(data_test[target], pred_label)\n",
    "  roc = roc_auc_score(data_test[target], predictions[:,1])\n",
    "  print('{} Accuracy score on test: {}'.format(algo, accuracy))\n",
    "  print('{} Precision score on test: {}'.format(algo, precision))\n",
    "  print('{} ROC score on test: {}'.format(algo, roc))\n",
    "  print('{} F1 score on test: {}'.format(algo, f1))\n",
    "  print('{} Classification Report: '.format(algo))\n",
    "  print(classification_report(data_test[target], pred_label))\n",
    "  newResult = {'Code_smell':target,'Algo':_algo,'Balance':_balance,'Ratio':_ratio , 'Accuracy':accuracy,'Precision':precision, 'F1_score':f1,'AUC':roc}\n",
    "  return newResult\n",
    "\n",
    "# 3. SEQUENTLY, CODE SMELL PREDICTING BY EACH OTHER MODELS\n",
    "features = list(df.select_dtypes(include=['int64', 'float64']).columns)\n",
    "target = 'Brain Class'\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# Split the Brain-class dataset into subsets: training-set, validation-set, and testing-set.\n",
    "y = df[target]\n",
    "X = df[features]\n",
    "\n",
    "id_pos = np.where(y.values.reshape(-1) == 1)[0]\n",
    "id_neg = np.where(y.values.reshape(-1) == 0)[0]\n",
    "\n",
    "np.random.shuffle(id_pos)\n",
    "np.random.shuffle(id_neg)\n",
    "\n",
    "train_pos_size = 500\n",
    "train_neg_size = 223500\n",
    "val_pos_size = 170\n",
    "val_neg_size = 74500\n",
    "\n",
    "# Creating training-set:\n",
    "id_train_pos = id_pos[:train_pos_size]\n",
    "id_train_neg = id_neg[:train_neg_size] \n",
    "id_train = np.concatenate((id_train_pos, id_train_neg), axis = 0)\n",
    "\n",
    "# Creating validation-set:\n",
    "id_val_pos = id_pos[train_pos_size:(train_pos_size + val_pos_size)]\n",
    "id_val_neg = id_neg[train_neg_size:(train_neg_size + val_neg_size)]\n",
    "id_val = np.concatenate((id_val_pos, id_val_neg), axis = 0)\n",
    "\n",
    "# Creating testing-set:\n",
    "id_test_pos = id_pos[(train_pos_size + val_pos_size):(train_pos_size + 2*val_pos_size)]\n",
    "id_test_neg = id_neg[(train_neg_size + val_neg_size):(train_neg_size + 2*val_neg_size)]\n",
    "id_test = np.concatenate((id_test_pos, id_test_neg), axis = 0)\n",
    "\n",
    "# initialize datasets\n",
    "data_train = df.iloc[id_train]\n",
    "data_val = df.iloc[id_val]\n",
    "data_test = df.iloc[id_test] \n",
    "\n",
    "## Using the Undersampling method, balancing the training-set in different ratios \n",
    "# Create the training-set in the ratio 80:20 (~ 4*train_pos_size:train_pos_size) by keeping 4*train_pos_size random negative samples from it.\n",
    "np.random.shuffle(id_train_neg)\n",
    "id_train_neg_80_20 = id_train_neg[:4*train_pos_size]\n",
    "id_train_80_20 = np.concatenate((id_train_neg_80_20, id_train_pos), axis = 0)\n",
    "\n",
    "# Create the training-set in the ratio 75:25 (~ 3*train_pos_size:train_pos_size) by keeping 3*train_pos_size random negative samples from it.\n",
    "np.random.shuffle(id_train_neg)\n",
    "id_train_neg_75_25 = id_train_neg[:3*train_pos_size]\n",
    "id_train_75_25 = np.concatenate((id_train_neg_75_25, id_train_pos), axis = 0) \n",
    "\n",
    "# Create the training-set in the ratio 60:40 (~ 1.5*train_pos_size:train_pos_size) by keeping 1.5*train_pos_size random negative samples from it.\n",
    "np.random.shuffle(id_train_neg)\n",
    "id_train_neg_60_40 = id_train_neg[:int(1.5*train_pos_size)]\n",
    "id_train_60_40 = np.concatenate((id_train_neg_60_40, id_train_pos), axis = 0) \n",
    "\n",
    "# initialize training-set\n",
    "data_train_80_20 = df.iloc[id_train_80_20]\n",
    "data_train_75_25 = df.iloc[id_train_75_25]\n",
    "data_train_60_40 = df.iloc[id_train_60_40]\n",
    "\n",
    "#The validation-set is used for model tuning to determine the best-selected model.\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_1 = RandomForestClassifier(n_estimators=100,\n",
    "                                max_depth=5,\n",
    "                                min_samples_split=200,\n",
    "                                class_weight=None,\n",
    "                                max_features=10)\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=500, \n",
    "                                max_depth=10, \n",
    "                                min_samples_split=400, \n",
    "                                random_state=12, \n",
    "                                class_weight=\"balanced\",\n",
    "                                max_features=\"sqrt\")\n",
    "\n",
    "model_3 = RandomForestClassifier(n_estimators=800, \n",
    "                                max_depth=10, \n",
    "                                min_samples_split=200, \n",
    "                                random_state=12, \n",
    "                                class_weight=\"balanced\",\n",
    "                                max_features=\"sqrt\")\n",
    "\n",
    "def _tunning_model(model , X_train, y_train, X_val, y_val):\n",
    "  model.fit(X_train, y_train)\n",
    "  model_predictions = model.predict_proba(X_val)\n",
    "  model_pred = model.predict(X_val[features]) \n",
    "  model_roc_score = roc_auc_score(y_val, \n",
    "                                  model_predictions[:,1])\n",
    "  model_f1_score = f1_score(y_val, model_pred)\n",
    "  return model, model_roc_score, model_f1_score\n",
    "\n",
    "model_1, model_1_roc_score, model_1_f1_score = _tunning_model(model_1, \n",
    "                                          data_train[features], data_train[target],\n",
    "                                          data_val[features], data_val[target])\n",
    "print('model 1 F1 score on val dataset: ', model_1_f1_score)\n",
    "#print('model 1 ROC score on validation-set: ', model_1_roc_score)\n",
    "\n",
    "model_2, model2_roc_score, model_2_f1_score = _tunning_model(model_2, \n",
    "                                          data_train[features], data_train[target],\n",
    "                                          data_val[features], data_val[target])\n",
    "print('model 2 F1 score on val dataset: ', model_2_f1_score)\n",
    "#print('model 2 ROC score on validation-set: ', model_2_roc_score)\n",
    "\n",
    "\n",
    "model_3, model3_roc_score, model_3_f1_score = _tunning_model(model_3, \n",
    "                                          data_train[features], data_train[target],\n",
    "                                          data_val[features], data_val[target])\n",
    "print('model 3 F1 score on val dataset: ', model_3_f1_score)\n",
    "#print('model 3 ROC score on validation-set: ', model_3_roc_score)\n",
    "\n",
    "#3.1 Creating the best-selected model using Random Forest Classifier algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC_model = RandomForestClassifier(n_estimators=100,\n",
    "                                max_depth=5,\n",
    "                                min_samples_split=200,\n",
    "                                class_weight=None,\n",
    "                                max_features=10)\n",
    "_algo = 'RFC'\n",
    "\n",
    "# Training & testing the model on the imbanlance training-set.\n",
    "_balance ='_None_'\n",
    "_ratio = '*'\n",
    "rs = pd.concat([rs, pd.DataFrame([_train_and_test(RFC_model, data_train, _algo + _balance + _ratio)])], ignore_index=True)\n",
    "\n",
    "#Training & testing the model on training-set with different ratio of Undersampling balancing method.\n",
    "_balance ='_unsam_'\n",
    "_ratio = '80_20'\n",
    "rs = pd.concat([rs, pd.DataFrame([_train_and_test(RFC_model, data_train_80_20, _algo + _balance + _ratio)])], ignore_index=True)\n",
    "\n",
    "_ratio = '75_25'\n",
    "rs = pd.concat([rs, pd.DataFrame([_train_and_test(RFC_model, data_train_75_25, _algo + _balance + _ratio)])], ignore_index=True)\n",
    "\n",
    "_ratio = '60_40'\n",
    "rs = pd.concat([rs, pd.DataFrame([_train_and_test(RFC_model, data_train_60_40, _algo + _balance + _ratio)])], ignore_index=True)\n",
    "\n",
    "#Training & testing the model on training-set with differrent Oversampling balancing method.\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import (RandomOverSampler, SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN)\n",
    "\n",
    "oversam = {0 : 'RandomOverSampler',\n",
    "          1 : 'SMOTE',\n",
    "          2 : 'BorderlineSMOTE',\n",
    "          3 : 'SVMSMOTE',\n",
    "          4 : 'ADASYN'}\n",
    "_balance ='_oversam_'\n",
    "for i, sampler in enumerate((RandomOverSampler(sampling_strategy = 1, random_state=0), \n",
    "                             SMOTE(sampling_strategy = 1, random_state=0),\n",
    "                             BorderlineSMOTE(sampling_strategy = 1, random_state=0, kind='borderline-1'),\n",
    "                             SVMSMOTE(sampling_strategy = 1, random_state=0),\n",
    "                             ADASYN(sampling_strategy = 1, random_state=0))):\n",
    "  pipe_line = make_pipeline(sampler, RFC_model)\n",
    "  _ratio = oversam[i]\n",
    "  rs = pd.concat([rs, pd.DataFrame([_train_and_test(pipe_line, data_train, _algo + _balance + _ratio)])], ignore_index=True)\n",
    "\n",
    "rs.to_csv('Class_BrainClass_RFC_rs.csv', header=True, sep=';', decimal=',') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
